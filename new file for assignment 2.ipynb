{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4010c9",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install and import required libraries\n",
    "!pip install selenium\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time \n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983dc12e",
   "metadata": {},
   "source": [
    "1.scraping data for data analyst post for bangalore location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b311e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening the required page(naukri.com) on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "#enter designation as required in question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Analyst')\n",
    "#enter location as required in question\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')\n",
    "#for clicking search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "\n",
    "#making blank list for required data given in questions\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "\n",
    "#scraping job title from given page\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "#scraping location from given page\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping company name from given page\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "#scraping experience from given page\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)\n",
    "job_title \n",
    "job_location\n",
    "company_name\n",
    "experience_required\n",
    " # printing length\n",
    "print(len(job_title),len(job_location),len(company_name ),len(experience_required ))\n",
    "\n",
    "\n",
    "# making dataframe\n",
    "df= pd.DataFrame({'Job':job_title,'Location':job_location,'Company':company_name,'Experience':experience_required} )\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa74e13",
   "metadata": {},
   "source": [
    "2.scraping a data for data scientist post in banglore location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening the required page(naukri.com) on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#enter designation as required in question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data scientist')\n",
    "#enter location as required in question\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')\n",
    "#for clicking search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "#making blank list for required data given in questions\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "\n",
    "#scraping job title from given page\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "#scraping location from given page\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "\n",
    "#scraping company name from given page\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "\n",
    "#scraping experience from given page\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)\n",
    "    \n",
    " # printing length\n",
    "print(len(job_title),len(job_location),len(company_name ),len(experience_required ))\n",
    "\n",
    "\n",
    "# making dataframe\n",
    "df= pd.DataFrame({'Job':job_title,'Location':job_location,'Company':company_name,'Experience':experience_required} )\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ee216",
   "metadata": {},
   "source": [
    "3.scraping a data for data scientist post in bangalore location with filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ab8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening the required page(naukri.com) on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#entering designation as required in question and click on search button\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "\n",
    "#scraping job title from given page\n",
    "title_tags = driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "#scraping location from given page\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#scraping company name from given page\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#scraping experience from given page\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')\n",
    "\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)\n",
    "    \n",
    "#printing length    \n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))\n",
    "\n",
    "# making dataframe\n",
    "df = pd.DataFrame({'Job Title':job_title,'Location':job_location,'Company':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa90631",
   "metadata": {},
   "source": [
    "4.scrap data for first 100 sunglasses from flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening the required page(naukri.com) on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "#enter product as required in question\n",
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK \")\n",
    "product.send_keys('Sunglasses')\n",
    "\n",
    "#for clicking search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "search.click()\n",
    "\n",
    "brand_name=[]\n",
    "product_description =[]\n",
    "price_of_product = []\n",
    "start = 0\n",
    "end = 3\n",
    "for pages in range(start,end):\n",
    "    brand = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    product = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    price = driver.find_elements(By.XPATH,'//a[@class=\"_3bPFwb\"]')\n",
    "    for i in brand:\n",
    "        brand_name.append(i.text)\n",
    "    for i in product:\n",
    "        product_description.append(i.text)\n",
    "    for i in price:\n",
    "        price_of_product.append(i.text)\n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')    \n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "Brand=brand_name0[0:100]\n",
    "Product=product_description[0:100]\n",
    "Price=price_of_product[0:100]\n",
    "#print(len(Brand),len(Product),len(Price))\n",
    "\n",
    "#making dataframe\n",
    "df=pd.DataFrame({'Brand':Brand,'Product':Product,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4e457b",
   "metadata": {},
   "source": [
    "5.100 review data from flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12348f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening the required page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART&q=apple+iphone11+black+64+gb&store=tyy%2F4io&spotlightTagId=BestsellerId_tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=Search&iid=76fc6167-eca7-4945-959e-70e6016e55e4.MOBFWQ6BXGJCEYNY.SEARCH&ppt=sp&ppn=sp&ssid=9fere6h3rk0000001670695888871&qH=faf1208381afa96c\")\n",
    "\n",
    "Rating_of_phone = []\n",
    "Review_summary = []\n",
    "Full_review = []\n",
    "start = 0\n",
    "end = 10\n",
    "for pages in range(start,end):\n",
    "    #scraping rating from given page\n",
    "    rating_tags = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating_tags:\n",
    "        rating = i.text\n",
    "        Rating_of_phone.append(rating)\n",
    "    \n",
    "    #scraping review from given page\n",
    "    review_tags = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_tags[0:10]:\n",
    "        review = i.text\n",
    "        Review_summary.append(review)\n",
    "    \n",
    "    #scraping full review from given page\n",
    "    full_tags = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_tags[0:10]:\n",
    "        full = i.text\n",
    "        Full_review.append(full)\n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')    \n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "#printing length    \n",
    "print(len(Rating_of_phone),len(Review_summary),len(Full_review))\n",
    "\n",
    "# making dataframe\n",
    "df = pd.DataFrame({'Rating_of_phone':Rating_of_phone,'Review_summary':Review_summary,'Full_review':Full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa959240",
   "metadata": {},
   "source": [
    "6.scrap a data for 100 sneakers from flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a848f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening the required page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "#enter product as required in question\n",
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK \")\n",
    "product.send_keys('Sneaker')\n",
    "\n",
    "#for clicking search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "search.click()\n",
    "# creating blank list to get result\n",
    "brand_name=[]\n",
    "product_description =[]\n",
    "price_of_product = []\n",
    "start = 0    \n",
    "end = 3    # defining starting and ending range of webpage\n",
    "\n",
    "# scraping brand,product description and price from webpage\n",
    "for pages in range(start,end):\n",
    "    brand = driver.find_elements(By.ID,'twotabsearchtextbox')\n",
    "    product = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    price = driver.find_elements(By.XPATH,'//a[@class=\"_3bPFwb\"]')\n",
    "    for i in brand:\n",
    "        brand_name.append(i.text)\n",
    "    for i in product:\n",
    "        product_description.append(i.text)\n",
    "    for i in price:\n",
    "        price_of_product.append(i.text)\n",
    "    next_button = driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')    \n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "Brand=brand_name[0:100]\n",
    "Description=product_description[0:100]\n",
    "Price=price_of_product[0:100]  \n",
    "\n",
    "#print(len(Brand),len(Description),len(Price)).....for printing and checking the length \n",
    "\n",
    "# making dataframe\n",
    "df = pd.DataFrame({'Brand Name':Brand,'Product Description':Description,'Price':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6363f1",
   "metadata": {},
   "source": [
    "7.scraping data for laptop from amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa5bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening the required page on automated chrome browser\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "#entering product as required in question and click on search button\n",
    "product = driver.find_element(By.ID,'twotabsearchtextbox')\n",
    "product.send_keys('Laptop')\n",
    "search = driver.find_element(By.XPATH,'//div[@class=\"nav-search-submit nav-sprite\"]')\n",
    "search.click()\n",
    "\n",
    "#creating a blank list \n",
    "laptop_title = []\n",
    "laptop_rating = []\n",
    "laptop_price = []\n",
    "\n",
    "\n",
    "#scraping laptop title from given page\n",
    "title_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    laptop_title.append(title)\n",
    "    \n",
    "#scraping rating from given page \n",
    "rating_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-size-base\"]')\n",
    "for i in rating_tags[0:10]:\n",
    "    rating = i.text\n",
    "    laptop_rating.append(rating)\n",
    "    \n",
    "#scraping price from given page\n",
    "price_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    price = i.text\n",
    "    laptop_price.append(price)\n",
    "    \n",
    "\n",
    "    \n",
    "#printing length    \n",
    "print(len(laptop_title),len(laptop_rating),len(laptop_price))\n",
    "\n",
    "# making dataframe\n",
    "df = pd.DataFrame({'laptop_title':laptop_title,'laptop_rating':laptop_rating,'laptop_price':laptop_price})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5a121",
   "metadata": {},
   "source": [
    "8.scrape data for top 1000 Quaotes of all time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aeac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening the required page on automated chrome browser\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "\n",
    "# creating blank list to get result\n",
    "Quotes=[]\n",
    "Author =[]\n",
    "Type_of_quotes = []\n",
    "\n",
    "# defining starting and ending range of webpage\n",
    "start = 0    \n",
    "end = 10    \n",
    "\n",
    "# scraping quote, author, type of quote from webpage\n",
    "for pages in range(start,end):\n",
    "    quote_page = driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    author_page = driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    type_page = driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    \n",
    "    for i in quote_page:\n",
    "        Quotes.append(i.text)\n",
    "    for i in author_page:\n",
    "        Author.append(i.text)\n",
    "    for i in  type_page:\n",
    "        Type_of_quotes.append(i.text)\n",
    "        \n",
    "    next_button = driver.find_elements(By.XPATH,'//li[@class=\"next\"][1]')    \n",
    "    next_button.click()\n",
    "    \n",
    "\n",
    "\n",
    "print(len(Quotes),len(Description),len(Price))   #.....for printing and checking the length \n",
    "\n",
    "# making dataframe\n",
    "df = pd.DataFrame({'Quotes':Quotes,'Author':Author,'Type of quotes':Type_of_quotes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e492cc04",
   "metadata": {},
   "source": [
    "9.display the list of former prime minister of india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3020dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening the required page on automated chrome browser\n",
    "driver.get(\"https://www.jagranjosh.com/\")\n",
    "#scraping table from given page\n",
    "table_tags = driver.find_elements(By.XPATH,'//div[@class=\"table-box\"][1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c6b7d",
   "metadata": {},
   "source": [
    "10.list of most 50 expensive car in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23926e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to the driver\n",
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "#opening the required page on automated chrome browser\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "\n",
    "#creating a blank list \n",
    "Car_name = []\n",
    "Car_description = []\n",
    "Car_price = []\n",
    "\n",
    "\n",
    "#scraping car name from given page\n",
    "name_tags = driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in name_tags[0:10]:\n",
    "    name = i.text\n",
    "    Car_name.append(name)\n",
    "    \n",
    "#scraping car description from given page \n",
    "description_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-size-base\"]')\n",
    "for i in description_tags[0:10]:\n",
    "    description = i.text\n",
    "    Car_description.append(description)\n",
    "    \n",
    "#scraping price from given page\n",
    "price_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    price = i.text\n",
    "    Car_price.append(price)\n",
    "    \n",
    "\n",
    "    \n",
    "#printing length    \n",
    "print(len(Car_name),len(Car_description),len(Car_price))\n",
    "\n",
    "# making dataframe\n",
    "df = pd.DataFrame({'Car_name':Car_name,'Car_description':Car_description,'Car_price':Car_price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fee5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
